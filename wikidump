#!/usr/bin/env ruby
gem 'slop', "~> 3.6"
require 'slop'
require 'epitools'

DUMPGENERATOR_URL = "https://raw.githubusercontent.com/WikiTeam/wikiteam/master/dumpgenerator.py"

def parse_argv
	opts = Slop.parse(help: true, strict: true) do
	  banner "Usage: wikidump [options] <wiki url(s)>"
	  separator "(Default behaviour: downloading the latest revision of each page, plus images.)"

	  on "i", "info", "Show info about the wiki, then exit"
	  on "a", "all", "Download all historical revisions for every page"
	  on "b", "boring", "No images"
	  on "d=", "dir", "Output directory"
	  on "U", "update", "Update dumpgenerator.py"
	end

	args = ARGV

	[opts,args]
end

failure = proc do |msg|
  $stderr.puts "<12>Error:</12> #{msg}".colorize
  $stderr.puts
  $stderr.puts opts
  exit 1
end

def wikidump(*args)
  update_dumpgenerator unless which("dumpgenerator.py")

  cmd = ["dumpgenerator.py", *args]
  puts "Executing: #{cmd.inspect}"
  system *cmd
end

def update_dumpgenerator
  out_file = "#{__DIR__}/dumpgenerator.py"
  puts "* getting #{DUMPGENERATOR_URL}"
  data = curl(DUMPGENERATOR_URL)
  puts "  |_ writing to #{out_file}"
  File.write(out_file, data)
  system("chmod", "+x", out_file) 
  system("git", "diff", out_file)
end

if opts.update?
  update_dumpgenerator
  exit
end

failure["Wiki URL missing"] if args.empty?

args.each do |url|
  failure["Invalid URL <8>(<1>\"<9>#{url}<1>\"<8>)"] unless url =~ %r{^https?://.+}
end

def info(url)
  # figure out what kind of url it is using the ext, protocol, and getting some partial ranges of data
end

if __FILE__ == $0
	args.each do |url|
          opts_for()
	def opts_for(url, )
	  if opts.info?
	    wikidump("--get-wiki-engine", url)
	  else
	    options = ["--xml"]
	    options << "--images" unless opts.boring?
	    options << "--curonly" unless opts[:all]

	    wikidump *options, url
	  end
	end
end
